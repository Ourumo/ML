*차원의 축소로 차원의 저주 해소

- 차원의 저주
샘플 특성이 많으면 학습이 어려워짐
샘플의 특성 = 차원 수, 공간이 넓어짐
공간이 넓어져서 학습이 어려워짐
차원이 하나씩 추가 될수록 학습해야하는 데이터의 양이 많아 지기 때문에 학습이 점점 어려워짐

- 차원 축소
특성 수를 줄여서 학습 불가능한 문제를 학습 가능한 문제로 만드는 기법
훈련 속도 증가, 일부 정보 유실 가능성
비어있는 공간은 필요 없으므로 샘플들이 분포하고 있는 공간들만

- 차원의 저주
차원이 커질 수록 두 지점 사이의 거리가 매우 커짐
많은 공간 = 데이터셋 희박
해결방안으로 샘플의 수를 늘리는 방법이 있으나
고차원의 경우 많은 샘플 수를 준비하는 일은 불가능

- 고차원 공간 데이터분포
대부분의 문제는 훈련 샘플이 모든 차원에 걸쳐 균일하게 퍼져 있지 않음
많은 특성은 거의 변화가 없는 반면, 다른 특성들은 서로 강하게 연관되어 있음
모든 훈련 샘플이 고차원 공간 안의 저차원 부분 공간에 놓여 있음

- 차원 감소 방법
기존 차원 공간 보다 작은 차원의 공간으로 데이터를 투영, 매니폴드 학습

- 투영
n차원 공간에 존재하는 d차원 공간으로 투영 (d < n)
예를 들어, 3차원을 2차원으로 투영
데이터가 있는 부분만 투영
차원 축소에 있어 언제나 최선의 방법은 아님 (반레: 스위스 롤)

- 스위스 롤 데이터 셋
부분 공간이 뒤틀리거나 휘어 있는 경우
스위스 롤 데이터 셋과 같은 데이터를 투영했을때 문제가 발생할수 있음

- 매니폴드 학습
2D 매니폴드 = 고차원 공간에서 휘어지거나 뒤틀린 2D모양
매니폴드 = 데이터가 있는 공간
고차원 공간의 데이터를
저차원의 매니폴드 공간으로 차원축소를 진행하면 보다 간단한 매니폴드가 된다는 가정 (3차원 -> 2,1차원으로 축소를 진행하면 간단해진다 가정)

- 투영을 하는 각도를 어떻게 설정할지??
데이터의 손실이 없으면서 투영할수 있는 방법?? -> PCA
- PCA(주성분 분석)
먼저 데이터에 가장 가까운 초평면을 정의 -> 데이터를 투영
투영했을때 얼마나 데이터가 잘 분리가 됬는지 -> 분산보존개념.....(중요)

- 분산 보존 
저차원으로 투영할 떄 훈련 세트의 분산이 최대로 보존되는 축을 선택
데이터셋 사이의 평균제곱고리를 최소화하는 축을 선택
제일 먼저 올바른 초평면을 선택

- 주성분 찾기
첫 번째 주성분 - 훈련세트에서 분산을 최대한 보존하는 축
두 번째 주성분 - 첫 번째 주성분과 수직을 이루면서 분산을 최대한 보존하는 축
세 번째 이후 - 이전의 주성분과 수직을 이루면서 분산을 최대한 보존
분산이 95% 까지 되도록 주성분 축을 찾아 나감
svd()함수: 파이썬 코드로 주성분을 구한 후 처음 두개의  PC를 정의하는 두 개의 단위 벡터를 추출

- 랜덤 PCA
확률적 알고리즘
처음 d개의 주성분에 대한 근삿값을 빠르게 찾음

- 점진적 PCA
훈련세트를 미니배치로 나눈 후 하나씩 주입
온라인 학습에 적용

- 커널 PCA
커널트릭을 PCA 적용해 차원 축소를 위한 복잡한 비선형 투영을 수행
샘플의 군집을 유지, 꼬여있는 매니폴드에 가까운 데이터 셋을 펼칠 때 유용

- LLE
비선형 차원축소 기법
투영이 아닌 매니폴드 학습
가장 가까운 이웃에 얼마나 선형적으로 연관되어 있는지
잡음이 너무 많지 않은 경우 꼬인 매니폴드를 펼치는 데 작동

- 다른 차원 축소 기법
이전 학습랜덤 투영, 다차원 스케일링, Isomap, t-SNE, 선형 판별 분석
==============================================================================
Q1: 충분한 분산은 95% 정도인데 90% 혹은 99%가 될 수는 없는가?
 90%는 가능할 것으로 여겨짐.
분산의 비율로 70% ~ 95%정도가 적당한 분산으로 생각하기 때문이다.
 하지만 99%는 불가능할 것으로 여겨짐.
모델의 학습 데이터가 100%가 되면 과대적합이 일어나게 되어 정확도의 문제가 생긴다. 그래서 이와 유사한 99%도 과대적합을 피할 수 없어서 불가능할 것이다.
분산의 높은 비율은 데이터의 차원을 크게 줄이지 않는 것을 의미함으로 99%는 거의 차원을 줄이지 않았다는 의미이기에 불가능할 것이다.

Q2: 주성분을 찾을 때, 첫 번째 주성분과 두 번째 주성분의 축이 왜 수직이어야 하는가?
주성분은 데이터의 분산을 최대화하는 방향으로 결정이 되는데, 같은 방향이나 유사한 방향으로 축을 생성하면 더 많은 데이터를 찾을 수 없을 것이다.
결론적으로 새로운 분산 정보를 많이 확보하기 위한 방향으로 축을 생성해야하는데 이를 위해서는 각각의 주성분이 독립적이어야한다.
이런 주성분이 서로 독립적이기 위해서는 서로의 축이 수직이어야한기에 각각의 주성분의 축은 수직이어야 한다.

Q3: 선형 차원축소와 비선형 차원축소 중 어느 것이 더 대중적인 차원축소 방법인가?
아마도 선형 차원축소가 더 대중적으로 쓰일 것이다.
선형 차원축소 방법들이 효율적이고 속도가 빠르기 때문이다.
물론 데이터의 구조가 선형인지 비선형인지에 따라 그에 맞는 차원축소 방법을 선택해야할 것이다.
